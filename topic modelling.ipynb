{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from math import ceil\n",
    "from math import floor\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый способ - вынуть слова из центра текста (больше по приколу, ну а вдруг повезёт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_punctuation = string.punctuation + '—»«...'\n",
    "file_texts = []\n",
    "for some_file in os.listdir('.'): \n",
    "    if not some_file.endswith('.txt'):\n",
    "        continue\n",
    "    with open(some_file, 'r', encoding='utf-8') as open_file:\n",
    "        file_texts.append(open_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_in_the_middle(some_text, num_words):\n",
    "    \"\"\"\n",
    "    На вход -- строка с текстом some_text, число слов в середине текста\n",
    "    \"\"\"\n",
    "    tokenized_text = [morph.parse(word)[0].normal_form for word in word_tokenize(some_text.lower()) if word not in extended_punctuation]\n",
    "    if len(tokenized_text) > num_words:\n",
    "        if num_words > 0:\n",
    "            return tokenized_text[floor(len(tokenized_text) / 2) - floor(num_words / 2) : ceil(len(tokenized_text) / 2) + floor(num_words / 2)]\n",
    "        else: \n",
    "            return None\n",
    "    else:\n",
    "        return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['в', 'прошлое', 'год', 'здесь', 'сойти', 'поезд', 'с', 'рельс', 'говорить', 'следователь']\n",
      "['батюшка', 'пётр', 'андрей', 'шептать', 'савельй', 'стоя', 'за', 'я', 'и', 'толкать', 'я']\n",
      "['от', 'ты', 'волк', 'не', 'хитро', 'уйти', 'сказка', 'колобок', 'картинка', '3', 'и']\n",
      "['использовать', 'тест-система', 'государственный', 'научный', 'центр', 'вектор', 'тоже', 'входящий', 'в', 'структура']\n",
      "['к', 'он', 'прибавиться', 'спорт', 'салон', 'красота', 'развлечение', 'говориться', 'в', 'исследование']\n"
     ]
    }
   ],
   "source": [
    "for text in file_texts:\n",
    "    print(keywords_in_the_middle(text, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем самые частотные леммы с помощью pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_lemmas_with_stopwords(some_text, num_most_freq, some_stoplist):\n",
    "    tags = ['PREP', 'CONJ', 'PRCL', 'INTJ', 'NPRO', 'VERB']\n",
    "    tokenized_text = [morph.parse(word)[0].normal_form for word in word_tokenize(some_text.lower()) if word.strip() \n",
    "                      not in extended_punctuation and morph.parse(word)[0].normal_form not in stoplist and morph.parse(word)[0].tag.POS not in tags]\n",
    "    return [word_freq_pair[0] for word_freq_pair in Counter(tokenized_text).most_common(num_most_freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['гайка', 'денис', 'грузило', 'следователь', 'рельс', 'благородие', 'поезд', 'глаз', 'григорьев', 'господин']\n",
      "['иван', 'пугачев', 'который', 'савельй', 'марья', 'крепость', 'швабрин', 'бог', 'комендант', 'человек']\n",
      "['колобок', 'короб', 'сусек', 'заяц', 'песенка', 'волк', 'лис', 'старуха', 'сметана', 'масло']\n",
      "['тест', 'тестирование', 'лаборатория', 'роспотребнадзор', 'коронавирус', 'биоматериал', 'регион', 'хеликс', 'государственный', 'представитель']\n",
      "['неделя', 'расход', 'россиянин', 'категория', 'товар', 'салон', 'красота', 'сбербанк', 'трата', 'сравнение']\n"
     ]
    }
   ],
   "source": [
    "stoplist = list(stopwords.words('russian'))\n",
    "stoplist.extend(['это', 'ваш', 'нешто', 'тебе', 'ежели', 'из-за', 'ту', 'эта', 'дальше', 'свой', 'весь', 'наш'])\n",
    "for text in file_texts:\n",
    "    print(most_frequent_lemmas_with_stopwords(text, 10, stoplist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF для униграмм и биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tf_idf = TfidfVectorizer(stop_words=stoplist, ngram_range=(1, 2)) \n",
    "texts_as_tfidf_vectors = make_tf_idf.fit_transform(file_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_tfidif(some_text):\n",
    "    tags = ['PREP', 'CONJ', 'PRCL', 'INTJ', 'NPRO', 'VERB']\n",
    "    lemmatized_text = [morph.parse(word)[0].normal_form for word in word_tokenize(some_text.lower()) if word.strip() \n",
    "                      not in extended_punctuation and morph.parse(word)[0].normal_form not in stoplist and morph.parse(word)[0].tag.POS not in tags]\n",
    "    return ' '.join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_tf_idf_keywords(some_texts, number_of_words):\n",
    "    result = []\n",
    "    texts_as_tfidf_vectors = make_tf_idf.fit_transform(preprocess_for_tfidif(text) for text in some_texts)\n",
    "    id2word = {i : word for i, word in enumerate(make_tf_idf.get_feature_names())} \n",
    "    for text_row in range(texts_as_tfidf_vectors.shape[0]):\n",
    "        row_data = texts_as_tfidf_vectors.getrow(text_row) \n",
    "        words_for_this_text = row_data.toarray().argsort()\n",
    "        top_words_for_this_text = words_for_this_text[0, : -1*(number_of_words+1) : -1]\n",
    "        result.append([id2word[w] for w in top_words_for_this_text])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['гайка', 'денис', 'грузило', 'следователь', 'рельс', 'поезд', 'благородие', 'григорьев', 'глаз', 'господь'], ['иван', 'пугачев', 'марья', 'савельй', 'марья иван', 'крепость', 'который', 'швабрин', 'бог', 'комендант'], ['колобок', 'колобок колобок', 'сусек', 'лис', 'короб', 'заяц', 'сметана', 'колобок картинка', 'сказка колобок', 'волк'], ['тест', 'тестирование', 'роспотребнадзор', 'лаборатория', 'коронавирус', 'биоматериал', 'регион', 'хеликс', 'представитель', 'государственный'], ['неделя', 'расход', 'россиянин', 'товар', 'категория', 'красота', 'трата', 'салон красота', 'салон', 'сбербанк']]\n"
     ]
    }
   ],
   "source": [
    "print(produce_tf_idf_keywords(file_texts, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/russia_today_1.jsonlines\", \"r\", encoding='utf-8') as read_file:\n",
    "    rt_1_data = [json.loads(line) for line in read_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталонные ключевые слова:  ['в россии', 'краснодар', 'рфпл', 'ростов', 'фк спартак', 'спорт', 'пфк цска', 'футбол']\n",
      "Слова из середины текста: ['присмотреться', 'к', 'возможность', 'сельт', 'и', 'тот', 'и', 'другой', 'не', 'привыкнуть', 'играть'] \n",
      "\n",
      "Эталонные ключевые слова:  ['в мире', 'евгений малкин', 'канада', 'кубок стэнли', 'нхл', 'россия', 'сша', 'спорт', 'спортсмен', 'хоккей', 'хоккей']\n",
      "Слова из середины текста: ['играть', 'в', 'меньшинство', 'но', 'большинство', 'питтсбург', 'из', 'преимущество', 'превратиться', 'в'] \n",
      "\n",
      "Эталонные ключевые слова:  ['анатолий антонов', 'вашингтон', 'госдеп сша', 'дипломаты', 'иноагент', 'мид', 'мария захарова', 'миротворец', 'посольство', 'сми', 'сша', 'хезер науэрт', 'цензура', 'внешняя политика']\n",
      "Слова из середины текста: ['rt', 'america', 'зарегистрироваться', 'в', 'качество', 'иностранный', 'агент', 'тогда', 'заместитель', 'руководитель'] \n",
      "\n",
      "Эталонные ключевые слова:  ['биржа', 'доллар', 'рубль', 'цифровая экономика', 'биткоин', 'криптовалюта', 'финансы']\n",
      "Слова из середины текста: ['криптовалюта', 'в', 'биткоина', 'спекулировать', 'но', 'с', 'другой', 'сторона', 'другой', 'известный'] \n",
      "\n",
      "Эталонные ключевые слова:  ['взрыв', 'взрыв в метро санкт-петербурга', 'исламское государство', 'киргизия', 'кыргызстан', 'метро', 'риа новости', 'акбаржон джалилов', 'происшествия']\n",
      "Слова из середины текста: ['рахат', 'сулайман', 'бывший', 'коллега', 'джалилов', 'рассказать', 'rt', 'о', 'предполагать', 'террорист'] \n",
      "\n",
      "Эталонные ключевые слова:  ['госдеп сша', 'дания', 'ес', 'евровидение', 'европа', 'канада', 'коррупция', 'правительство', 'сша', 'украина', 'эксклюзив rt', 'европа', 'сша', 'украина']\n",
      "Слова из середины текста: ['результат', 'удаться', 'добиться', 'вашингтон', 'в', 'киев', 'однако', 'сам', 'президент', 'украина', 'пётр'] \n",
      "\n",
      "Эталонные ключевые слова:  ['в мире', 'владимир путин', 'выборы', 'выборы в сша', 'дональд трамп', 'россия', 'сша', 'спецслужбы', 'цру', 'сша']\n",
      "Слова из середины текста: ['стивен', 'мнучин', 'считать', 'что', 'вмешательство', 'россия', 'даже', 'если', 'оно', 'и'] \n",
      "\n",
      "Эталонные ключевые слова:  ['ibf', 'wba', 'wbc', 'wbo', 'андре уорд', 'бокс', 'в мире', 'дмитрий бивол', 'россия', 'россияне', 'сша', 'сергей ковалёв', 'спорт', 'спортсмен', 'тренер', 'украина', 'бокс/мма']\n",
      "Слова из середины текста: ['такой', 'удар', 'застать', 'украинец', 'врасплох', 'один', 'нокдаун', 'стать', 'лишь', 'начало'] \n",
      "\n",
      "Эталонные ключевые слова:  ['дональд трамп', 'республиканская партия', 'сша', 'выборы в сша']\n",
      "Слова из середины текста: ['крайне', 'жёсткий', 'партийный', 'противостояние', 'между', 'республиканец', 'и', 'демократ', 'исход', 'который'] \n",
      "\n",
      "Эталонные ключевые слова:  ['ангела меркель', 'беженцы', 'выборы в германии ', 'германия', 'информационная война', 'мигранты', 'новый год 2017', 'парламентские выборы', 'хакеры', 'европа']\n",
      "Слова из середины текста: ['вещий', 'про', 'иисус', 'а', 'затем', 'они', 'запустить', 'фейерверк', 'в', 'церковь'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in rt_1_data[:10]:\n",
    "    print('Эталонные ключевые слова: ', item['keywords'])\n",
    "    print('Слова из середины текста:', keywords_in_the_middle(item['content'], 10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_keywords = [] \n",
    "full_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in rt_1_data:\n",
    "    if item['content']:\n",
    "        manual_keywords.append(item['keywords'])\n",
    "        full_texts.append(item['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталонные ключевые слова:  ['в россии', 'краснодар', 'рфпл', 'ростов', 'фк спартак', 'спорт', 'пфк цска', 'футбол']\n",
      "Слова из середины текста: ['команда', 'клуб', 'лига', 'болельщик', 'сезон', 'спартак', 'томь', 'игрок', 'цска', 'лига европа'] \n",
      "\n",
      "Эталонные ключевые слова:  ['в мире', 'евгений малкин', 'канада', 'кубок стэнли', 'нхл', 'россия', 'сша', 'спорт', 'спортсмен', 'хоккей', 'хоккей']\n",
      "Слова из середины текста: ['нэшвилл', 'питтсбург', 'матч', 'кубок стэнли', 'стэнли', 'команда', 'серия', 'защитник', 'гость', 'кубок'] \n",
      "\n",
      "Эталонные ключевые слова:  ['анатолий антонов', 'вашингтон', 'госдеп сша', 'дипломаты', 'иноагент', 'мид', 'мария захарова', 'миротворец', 'посольство', 'сми', 'сша', 'хезер науэрт', 'цензура', 'внешняя политика']\n",
      "Слова из середины текста: ['сми', 'мера', 'сша', 'иностранный агент', 'российский', 'агент', 'иностранный', 'посольство', 'российский сми', 'американский'] \n",
      "\n",
      "Эталонные ключевые слова:  ['биржа', 'доллар', 'рубль', 'цифровая экономика', 'биткоин', 'криптовалюта', 'финансы']\n",
      "Слова из середины текста: ['биткоина', 'криптовалюта', 'цена', 'тысяча', 'валюта', 'декабрь', 'шевцов', 'курс', 'фьючерс', 'биржа'] \n",
      "\n",
      "Эталонные ключевые слова:  ['взрыв', 'взрыв в метро санкт-петербурга', 'исламское государство', 'киргизия', 'кыргызстан', 'метро', 'риа новости', 'акбаржон джалилов', 'происшествия']\n",
      "Слова из середины текста: ['петербург', 'взрыв', 'джалил', 'санкт', 'санкт петербург', 'метро', 'киргизия', 'уроженец', 'петербургский метро', 'проспект'] \n",
      "\n",
      "Эталонные ключевые слова:  ['госдеп сша', 'дания', 'ес', 'евровидение', 'европа', 'канада', 'коррупция', 'правительство', 'сша', 'украина', 'эксклюзив rt', 'европа', 'сша', 'украина']\n",
      "Слова из середины текста: ['украина', 'коррупция', 'канада', 'миллион', 'реформа', 'сфера', 'украинский', 'киев', 'экономический', 'степан'] \n",
      "\n",
      "Эталонные ключевые слова:  ['в мире', 'владимир путин', 'выборы', 'выборы в сша', 'дональд трамп', 'россия', 'сша', 'спецслужбы', 'цру', 'сша']\n",
      "Слова из середины текста: ['трамп', 'путин', 'бреннана', 'американский', 'выбор', 'сша', 'лидер', 'владимир путин', 'россия', 'дональд'] \n",
      "\n",
      "Эталонные ключевые слова:  ['ibf', 'wba', 'wbc', 'wbo', 'андре уорд', 'бокс', 'в мире', 'дмитрий бивол', 'россия', 'россияне', 'сша', 'сергей ковалёв', 'спорт', 'спортсмен', 'тренер', 'украина', 'бокс/мма']\n",
      "Слова из середины текста: ['ковалёва', 'шабранский', 'боксёр', 'бокс', 'украинец', 'бой', 'поединок', 'боксёрский', 'титул', 'россиянин'] \n",
      "\n",
      "Эталонные ключевые слова:  ['дональд трамп', 'республиканская партия', 'сша', 'выборы в сша']\n",
      "Слова из середины текста: ['трамп', 'мэттис', 'габбард', 'назначение', 'партия', 'сша', 'пост', 'конгресс', 'представитель', 'болтон'] \n",
      "\n",
      "Эталонные ключевые слова:  ['ангела меркель', 'беженцы', 'выборы в германии ', 'германия', 'информационная война', 'мигранты', 'новый год 2017', 'парламентские выборы', 'хакеры', 'европа']\n",
      "Слова из середины текста: ['церковь', 'мигрант', 'фейерверк', 'площадь', 'полиция', 'дортмунд', 'хакер', 'полицейский', 'германия', 'полицейский сводка'] \n",
      "\n",
      "Эталонные ключевые слова:  ['венгрия', 'плавание', 'россия', 'россияне', 'спорт', 'спортсмен', 'чемпионат мира по водным видам спорта 2017', 'юлия ефимова', 'летние виды']\n",
      "Слова из середины текста: ['метр', '200 метр', 'рылов', '200', 'дистанция', 'пловец', 'победа', 'чупковы', 'ефимов', 'плавание'] \n",
      "\n",
      "Эталонные ключевые слова:  ['в россии', 'в мире', 'кубок федерации', 'россия', 'сборная россии по теннису', 'спорт', 'спортсмен', 'теннис', 'теннис']\n",
      "Слова из середины текста: ['клейбанов', 'турнир', 'алиса', 'россиянка', 'корт', 'теннисистка', 'возвращение', 'год', 'испытание', 'wta'] \n",
      "\n",
      "Эталонные ключевые слова:  ['авиалинии', 'авиация', 'египет', 'исламское государство', 'ливия', 'море', 'переговоры', 'теракт', 'терроризм', 'туризм', 'турист', 'эксклюзив rt', 'внешняя политика']\n",
      "Слова из середины текста: ['египет', 'терроризм', 'эль минья', 'минья', 'египетский', 'эль', 'террористический', 'безопасность', 'международный', 'вопрос'] \n",
      "\n",
      "Эталонные ключевые слова:  ['белоруссия', 'германия', 'канада', 'россияне', 'сша', 'спорт', 'спортсмен', 'финляндия', 'франция', 'чехия', 'швеция', 'чемпионат мира по хоккею — 2017', 'чм по хоккею — 2017']\n",
      "Слова из середины текста: ['шайба', 'матч', 'чех', 'минута', 'период', 'первое период', 'ворот', 'счёт', 'команда', 'красный машина'] \n",
      "\n",
      "Эталонные ключевые слова:  ['cas', 'аделина сотникова', 'александр легков', 'дисквалификация', 'допинг', 'лыжный спорт', 'мок', 'олимпийские игры', 'олимпийские игры 2014 в сочи', 'спорт', 'спортсмен', 'допинг', 'зимние виды']\n",
      "Слова из середины текста: ['проба', 'спортсмен', 'медаль', 'лыжник', 'олимпиада', 'олимпийский', 'wada', 'пробирка', 'спринт', 'лыжный'] \n",
      "\n",
      "Эталонные ключевые слова:  ['аргентина', 'барселона', 'договор', 'криштиану роналду', 'лионель месси', 'спорт', 'спортсмен', 'финансы', 'футбол']\n",
      "Слова из середины текста: ['месси', 'барселона', 'клуб', 'роналда', 'контракт', 'аргентинец', 'игрок', 'сумма', 'миллион', 'новый контракт'] \n",
      "\n",
      "Эталонные ключевые слова:  ['барак обама', 'дональд трамп', 'прослушка в сша', 'сша', 'эксклюзив rt', 'сша']\n",
      "Слова из середины текста: ['обама', 'петиция', 'экс президент', 'трамп', 'экс', 'администрация', 'информация', 'национальный', 'мухин', 'утечка'] \n",
      "\n",
      "Эталонные ключевые слова:  ['армия', 'балканы', 'вооруженный конфликт', 'донбасс', 'европа', 'запад', 'история', 'киев', 'преступление', 'сербия', 'слободан милошевич', 'украина', 'хорватия', 'гаагский суд', 'ес', 'ксенофобия', 'нато', 'национализм', 'сша', 'суд', 'европа']\n",
      "Слова из середины текста: ['хорватия', 'сербский', 'серб', 'краина', 'хорватский', 'хорват', 'сербский краина', 'республика', 'территория', 'югославия'] \n",
      "\n",
      "Эталонные ключевые слова:  ['долг', 'киев', 'мвф', 'пётр порошенко', 'россия', 'ссср', 'суд', 'украина', 'украина']\n",
      "Слова из середины текста: ['долг', 'украина', 'суд', 'сумма', 'киев', 'судебный', 'высокий суд', 'минфин', 'издержка', 'украинский'] \n",
      "\n",
      "Эталонные ключевые слова:  ['александр новак', 'нефть', 'опек', 'экономика', 'энергетика', 'мировая экономика', 'энергетика']\n",
      "Слова из середины текста: ['нефть', 'баррель', 'опека', 'добыча', 'цена', 'цена нефть', 'картель', 'добыча нефть', 'участник', 'год'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for manual_keywords_group, predicted_keywords_group in zip(manual_keywords[:20], produce_tf_idf_keywords(full_texts[:20], 10)):\n",
    "    print('Эталонные ключевые слова: ', manual_keywords_group)\n",
    "    print('Слова из середины текста:', predicted_keywords_group, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keywords_tf_idf = produce_tf_idf_keywords(full_texts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keywords_in_the_middle = [keywords_in_the_middle(text, 10) for text in full_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_most_frequent_lemmas_with_stopwords = [most_frequent_lemmas_with_stopwords(text, 10, stoplist) for text in full_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_fmeasure_jaccard(manual, predicted):\n",
    "    \"\"\"\n",
    "    считает точность, полноту, F-меру и коэффицент Жаккара\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    intersections = []\n",
    "    for index, words_manual in enumerate(manual):\n",
    "        words_predicted = predicted[index]\n",
    "        intersection = len(set(words_manual) & set(words_predicted))\n",
    "        recalls.append(intersection / len(words_manual)) \n",
    "        if len(words_predicted) == 0:\n",
    "            print(len(full_texts[index]))\n",
    "        precisions.append(intersection / len(words_predicted))\n",
    "        intersections.append(intersection)\n",
    "    mean_precision = sum(precisions) / len(precisions)\n",
    "    mean_recall = sum(recalls) / len(recalls)\n",
    "    fmeasure = ((2 * mean_recall * mean_precision) / (mean_recall + mean_precision))\n",
    "    jaccard_index = sum(intersections) / (len([words_manual for words_manual in manual]) + len([words_predicted for words_predicted in predicted]) - sum(intersections))\n",
    "    return f'Точность: {mean_precision}, полнота: {mean_recall}, F-мера {fmeasure}, коэффицент Жаккара {jaccard_index}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Точность: 0.11011011011010972, полнота: 0.11226604304272218, F-мера 0.1111776257102956, коэффицент Жаккара 1.2249443207126949'"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fmeasure_jaccard(manual_keywords, predicted_keywords_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Точность: 0.02687882687882691, полнота: 0.030870581882303676, F-мера 0.028736745323064892, коэффицент Жаккара 0.16365754222481071'"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fmeasure_jaccard(manual_keywords, predicted_keywords_in_the_middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Точность: 0.14583750417083668, полнота: 0.14840256643236568, F-мера 0.14710885472991353, коэффицент Жаккара 2.6863468634686347'"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fmeasure_jaccard(manual_keywords, predicted_most_frequent_lemmas_with_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
